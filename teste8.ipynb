{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a51ec2-06d3-40c0-8cd9-a2604a3aff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lilia/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\lilia/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
      "Using cache found in C:\\Users\\lilia/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import threading\n",
    "from queue import Queue\n",
    "import pyttsx3\n",
    "\n",
    "############################################\n",
    "# CONFIG PRINCIPAL\n",
    "############################################\n",
    "FAST_MODE = True\n",
    "FRAME_SKIP = 2\n",
    "USE_FLOW = False\n",
    "\n",
    "############################################\n",
    "# 1) MODELOS: YOLO + MiDaS\n",
    "############################################\n",
    "yolo = YOLO('yolov8n.pt')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "midas = torch.hub.load('intel-isl/MiDaS', 'MiDaS_small', trust_repo=True).to(device).eval()\n",
    "transform = torch.hub.load('intel-isl/MiDaS', 'transforms', trust_repo=True).small_transform\n",
    "\n",
    "############################################\n",
    "# 2) CONFIGS DO PROJETO\n",
    "############################################\n",
    "CLASSES_UTEIS = ['person','bicycle','car','bench','chair','stop sign','potted plant']\n",
    "\n",
    "def get_roi(frame):\n",
    "    h, w = frame.shape[:2]\n",
    "    x1, x2 = int(w*0.10), int(w*0.70)\n",
    "    y1, y2 = int(h*0.35), int(h*0.75)\n",
    "    return (x1, y1, x2, y2)\n",
    "\n",
    "DIST_DANGER_M = 2.5\n",
    "FLOW_APPROACH_MIN = 0.6\n",
    "CENTER_BONUS = 0.15\n",
    "\n",
    "############################################\n",
    "# 3) FUNÇÕES UTILITÁRIAS (com calibração automática + debug visual)\n",
    "############################################\n",
    "\n",
    "FOV_H_DEG = 75.0\n",
    "PERSON_HEIGHT_M = 1.55\n",
    "CAMERA_HEIGHT_M = 1.0\n",
    "_dynamic_scale = 4.0\n",
    "_focal_px = None\n",
    "_last_debug_dist = None\n",
    "_calibrating_frames = 0\n",
    "\n",
    "def predict_depth(frame_bgr):\n",
    "    if FAST_MODE:\n",
    "        frame_bgr = cv2.resize(frame_bgr, (frame_bgr.shape[1]//2, frame_bgr.shape[0]//2))\n",
    "    img_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    inp = transform(img_rgb).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = midas(inp)\n",
    "        pred = torch.nn.functional.interpolate(\n",
    "            pred.unsqueeze(1),\n",
    "            size=img_rgb.shape[:2],\n",
    "            mode='bicubic',\n",
    "            align_corners=False\n",
    "        ).squeeze().cpu().numpy()\n",
    "    pred_norm = (pred - pred.min()) / (pred.max() - pred.min() + 1e-6)\n",
    "    pred_norm = cv2.medianBlur((pred_norm*255).astype(np.uint8), 5)\n",
    "    pred_norm = pred_norm.astype(np.float32)/255.0\n",
    "    if FAST_MODE:\n",
    "        pred_norm = cv2.resize(pred_norm, (frame_bgr.shape[1]*2, frame_bgr.shape[0]*2))\n",
    "    return pred_norm\n",
    "\n",
    "def _auto_calibrate_scale(yolo_results, invdepth, frame_shape):\n",
    "    \"\"\"\n",
    "    Ajusta automaticamente o fator de escala com base em uma pessoa detectada.\n",
    "    \"\"\"\n",
    "    global _dynamic_scale, _focal_px, _last_debug_dist, _calibrating_frames\n",
    "    h, w = frame_shape[:2]\n",
    "    if _focal_px is None:\n",
    "        _focal_px = (w / 2) / np.tan(np.deg2rad(FOV_H_DEG / 2))\n",
    "\n",
    "    person_boxes = []\n",
    "    for r in yolo_results:\n",
    "        for b in r.boxes:\n",
    "            cls = yolo.names[int(b.cls)]\n",
    "            if cls == 'person' and float(b.conf) > 0.6:\n",
    "                x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "                cx = (x1 + x2) / 2\n",
    "                person_boxes.append((abs(cx - w/2), (x1, y1, x2, y2)))\n",
    "    if not person_boxes:\n",
    "        return\n",
    "\n",
    "    _, (x1, y1, x2, y2) = min(person_boxes, key=lambda t: t[0])\n",
    "    h_box = max(1, y2 - y1)\n",
    "\n",
    "    d_geom = (_focal_px * PERSON_HEIGHT_M) / h_box\n",
    "\n",
    "    box_depth = invdepth[y1:y2, x1:x2]\n",
    "    if box_depth.size == 0:\n",
    "        return\n",
    "    inv_med = float(np.median(box_depth))\n",
    "    d_midas = _dynamic_scale / max(inv_med, 1e-3)\n",
    "\n",
    "    scale_factor = d_geom / max(d_midas, 1e-3)\n",
    "    _dynamic_scale = 0.9 * _dynamic_scale + 0.1 * (_dynamic_scale * scale_factor)\n",
    "\n",
    "    _last_debug_dist = d_geom\n",
    "    _calibrating_frames += 1\n",
    "\n",
    "def invdepth_to_meters(invdepth):\n",
    "    inv = max(float(invdepth), 1e-3)\n",
    "    d_midas = _dynamic_scale / inv\n",
    "    dh = max(0.0, PERSON_HEIGHT_M - CAMERA_HEIGHT_M)\n",
    "    if d_midas > dh:\n",
    "        d_midas = (d_midas ** 2 - dh ** 2) ** 0.5\n",
    "    return d_midas\n",
    "\n",
    "def bbox_center(b):\n",
    "    x1, y1, x2, y2 = b\n",
    "    return (int((x1 + x2)//2), int((y1 + y2)//2))\n",
    "\n",
    "def mean_flow_in_bbox(flow, bbox):\n",
    "    if not USE_FLOW or flow is None:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    fx, fy = flow[y1:y2, x1:x2, 0], flow[y1:y2, x1:x2, 1]\n",
    "    if fx.size == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    mag = np.sqrt(fx*fx + fy*fy)\n",
    "    return float(np.mean(fx)), float(np.mean(fy)), float(np.mean(mag))\n",
    "\n",
    "def center_weight_in_roi(cx, cy, roi):\n",
    "    x1, y1, x2, y2 = roi\n",
    "    rx, ry = (x1 + x2)/2, (y1 + y2)/2\n",
    "    rw, rh = (x2 - x1), (y2 - y1)\n",
    "    dx, dy = abs(cx - rx)/(rw/2 + 1e-6), abs(cy - ry)/(rh/2 + 1e-6)\n",
    "    d = np.sqrt(dx*dx + dy*dy)\n",
    "    return max(0.0, 1.0 - min(1.0, d))\n",
    "\n",
    "############################################\n",
    "# 4) TTS + RATE-LIMITING\n",
    "############################################\n",
    "\n",
    "def _init_tts_engine():\n",
    "    eng = pyttsx3.init()\n",
    "    try:\n",
    "        for v in eng.getProperty('voices'):\n",
    "            name = (v.name or '').lower()\n",
    "            lang = ''.join(v.languages).lower() if hasattr(v, 'languages') else ''\n",
    "            if 'pt' in lang or 'portugu' in name:\n",
    "                eng.setProperty('voice', v.id)\n",
    "                if 'br' in lang or 'braz' in name:\n",
    "                    break\n",
    "    except: pass\n",
    "    eng.setProperty('rate', 180)\n",
    "    eng.setProperty('volume', 1.0)\n",
    "    return eng\n",
    "\n",
    "_tts_engine = _init_tts_engine()\n",
    "_tts_queue = Queue(maxsize=6)\n",
    "_tts_lock = threading.Lock()\n",
    "\n",
    "def _tts_worker():\n",
    "    while True:\n",
    "        t = _tts_queue.get()\n",
    "        try:\n",
    "            _tts_engine.say(t)\n",
    "            _tts_engine.runAndWait()\n",
    "        except: pass\n",
    "        _tts_queue.task_done()\n",
    "\n",
    "threading.Thread(target=_tts_worker, daemon=True).start()\n",
    "\n",
    "_last_speak_ts = 0.0\n",
    "_last_alert_ts = 0.0\n",
    "MIN_SPEAK_GAP_S = 0.1\n",
    "MIN_ALERT_GAP_S = 0.1\n",
    "per_target_cooldown = {}\n",
    "TARGET_COOLDOWN_S = 0.5\n",
    "\n",
    "NOMES_PT = {\n",
    "    'person': 'pessoa',\n",
    "    'bicycle': 'bicicleta',\n",
    "    'car': 'carro',\n",
    "    'bench': 'banco',\n",
    "    'chair': 'cadeira',\n",
    "    'stop sign': 'placa de pare',\n",
    "    'potted plant': 'planta'\n",
    "}\n",
    "\n",
    "def _fmt_metros(x): return f\"{x:.1f}\".replace('.', ',')\n",
    "def _dir_from_bbox(center, roi):\n",
    "    cx, cy = center; x1, y1, x2, y2 = roi\n",
    "    t = (x1 + (x2 - x1)/3, x1 + 2*(x2 - x1)/3)\n",
    "    return \"à esquerda\" if cx < t[0] else \"à direita\" if cx > t[1] else \"à frente\"\n",
    "\n",
    "def speak(txt, priority=False):\n",
    "    global _last_speak_ts, _last_alert_ts\n",
    "    now = time.time()\n",
    "    if priority:\n",
    "        if now - _last_alert_ts < MIN_ALERT_GAP_S: return\n",
    "        with _tts_lock:\n",
    "            try:\n",
    "                while not _tts_queue.empty():\n",
    "                    _tts_queue.get_nowait(); _tts_queue.task_done()\n",
    "            except: pass\n",
    "        _last_alert_ts = now\n",
    "    else:\n",
    "        if now - _last_speak_ts < MIN_SPEAK_GAP_S: return\n",
    "        _last_speak_ts = now\n",
    "    try:\n",
    "        _tts_queue.put_nowait(txt)\n",
    "    except: pass\n",
    "\n",
    "############################################\n",
    "# 5) LOOP PRINCIPAL\n",
    "############################################\n",
    "\n",
    "video_path = 'video_certo_edat.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "prev_gray = None\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok: break\n",
    "    frame_idx += 1\n",
    "    if FAST_MODE and frame_idx % (FRAME_SKIP+1) != 0:\n",
    "        continue\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    roi = get_roi(frame)\n",
    "    cv2.rectangle(frame, (roi[0], roi[1]), (roi[2], roi[3]), (255, 255, 0), 2)\n",
    "\n",
    "    invdepth = predict_depth(frame)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    flow = None\n",
    "    if USE_FLOW:\n",
    "        if prev_gray is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 21, 3, 5, 1.2, 0)\n",
    "        prev_gray = gray.copy()\n",
    "\n",
    "    results = yolo(frame, verbose=False)\n",
    "    \n",
    "    # --- DESFOCAR PESSOAS (PRIVACIDADE) ---\n",
    "    for r in results:\n",
    "        for b in r.boxes:\n",
    "            cls = yolo.names[int(b.cls)]\n",
    "            if cls == 'person' and float(b.conf) > 0.5:\n",
    "                x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "                # Garante que as coordenadas fiquem dentro dos limites\n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "\n",
    "                # Recorte da região da pessoa\n",
    "                pessoa = frame[y1:y2, x1:x2]\n",
    "                if pessoa.size == 0:\n",
    "                    continue\n",
    "\n",
    "                # Aplica blur forte (pode trocar por pixelização se quiser)\n",
    "                pessoa_blur = cv2.GaussianBlur(pessoa, (51, 51), 30)\n",
    "                frame[y1:y2, x1:x2] = pessoa_blur\n",
    "    # ---------------------------------------\n",
    "\n",
    "    _auto_calibrate_scale(results, invdepth, frame.shape)\n",
    "\n",
    "    candidates = []\n",
    "    for r in results:\n",
    "        for b in r.boxes:\n",
    "            cls = yolo.names[int(b.cls)]; conf = float(b.conf)\n",
    "            if conf < 0.45 or cls not in CLASSES_UTEIS: continue\n",
    "            x1, y1, x2, y2 = map(int, b.xyxy[0])\n",
    "            cx, cy = bbox_center((x1, y1, x2, y2))\n",
    "            if not (roi[0] < cx < roi[2] and roi[1] < cy < roi[3]): continue\n",
    "\n",
    "            x1c, y1c = max(0, x1), max(0, y1)\n",
    "            x2c, y2c = min(w, x2), min(h, y2)\n",
    "            box_depth = invdepth[y1c:y2c, x1c:x2c]\n",
    "            if box_depth.size == 0: continue\n",
    "            inv_med = float(np.median(box_depth))\n",
    "            dist_m = invdepth_to_meters(inv_med)\n",
    "            mx, my, mmag = mean_flow_in_bbox(flow, (x1c, y1c, x2c, y2c))\n",
    "            approach = mmag + max(0.0, -my)\n",
    "            cweight = center_weight_in_roi(cx, cy, roi)\n",
    "            candidates.append({\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'cls': cls,\n",
    "                'conf': conf,\n",
    "                'dist_m': dist_m,\n",
    "                'flow_mag': mmag,\n",
    "                'approach': approach,\n",
    "                'center_w': cweight,\n",
    "                'center': (cx, cy)\n",
    "            })\n",
    "\n",
    "    target = None\n",
    "    if candidates:\n",
    "        for c in candidates:\n",
    "            inv_d = 1.0 / (c['dist_m'] + 1e-6)\n",
    "            c['score'] = 1.5*inv_d + 1.0*c['center_w'] + 0.8*c['approach']\n",
    "        target = max(candidates, key=lambda x: x['score'])\n",
    "\n",
    "    for c in candidates:\n",
    "        x1, y1, x2, y2 = c['bbox']\n",
    "        color = (0, 0, 255) if target and c is target else (0, 255, 0)\n",
    "        txt = f\"{c['cls']} {c['dist_m']:.1f}m\"\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(frame, txt, (x1, max(20, y1-8)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "    # --- DEBUG VISUAL ---\n",
    "    status = \"CALIBRANDO...\" if _calibrating_frames < 15 else \"OK\"\n",
    "    scale_txt = f\"Escala: {_dynamic_scale:.2f} | {status}\"\n",
    "    cv2.putText(frame, scale_txt, (15, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (50, 255, 50), 2)\n",
    "    if _last_debug_dist:\n",
    "        cv2.putText(frame, f\"Ref pessoa: {_last_debug_dist:.1f}m\", (15, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
    "    # --------------------\n",
    "\n",
    "    alert_text = \"\"\n",
    "    if target:\n",
    "        near = target['dist_m'] <= DIST_DANGER_M\n",
    "        fast = target['approach'] >= FLOW_APPROACH_MIN\n",
    "        centered = target['center_w'] >= (1.0 - CENTER_BONUS)\n",
    "        if (near and fast) or (near and centered):\n",
    "            alert_text = f\"ALERTA: {target['cls']} a {target['dist_m']:.1f} m\"\n",
    "            cv2.putText(frame, alert_text, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 3)\n",
    "\n",
    "    if target:\n",
    "        direction = _dir_from_bbox(target['center'], roi)\n",
    "        alvo_key = (target['cls'], direction)\n",
    "        if alert_text:\n",
    "            cls_pt = NOMES_PT.get(target['cls'], target['cls'])\n",
    "            dist_txt = _fmt_metros(target['dist_m'])\n",
    "            acao = \"Pare.\" if direction == \"à frente\" else \\\n",
    "                   \"Desvie à esquerda.\" if direction == \"à direita\" else \"Desvie à direita.\"\n",
    "            fala = f\"Alerta! {cls_pt} a {dist_txt} metros {direction}. {acao}\"\n",
    "            speak(fala, priority=True)\n",
    "        else:\n",
    "            now = time.time()\n",
    "            if now - per_target_cooldown.get(alvo_key, 0.0) >= TARGET_COOLDOWN_S:\n",
    "                cls_pt = NOMES_PT.get(target['cls'], target['cls'])\n",
    "                dist_txt = _fmt_metros(target['dist_m'])\n",
    "                speak(f\"{cls_pt} a {dist_txt} metros {direction}.\", priority=False)\n",
    "                per_target_cooldown[alvo_key] = now\n",
    "\n",
    "    cv2.imshow(\"Etapa 4 - Modo Rápido CPU (AutoCalib + Debug)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
